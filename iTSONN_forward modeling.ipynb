{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d217614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MobileEmuMaster\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Loss: 2.9156e+00 | PDE Loss: 1.3194e+00 | Relative Error: 8.5111e-01 | Exact Solution MSE: 3.0296e+01\n",
      "Epoch 2/100 | Loss: 1.6870e+00 | PDE Loss: 5.5506e-01 | Relative Error: 7.8030e-01 | Exact Solution MSE: 2.5465e+01\n",
      "Epoch 3/100 | Loss: 1.2037e+00 | PDE Loss: 2.8559e-01 | Relative Error: 7.2681e-01 | Exact Solution MSE: 2.2093e+01\n",
      "Epoch 4/100 | Loss: 1.0197e+00 | PDE Loss: 1.7337e-01 | Relative Error: 6.8117e-01 | Exact Solution MSE: 1.9406e+01\n",
      "Epoch 5/100 | Loss: 9.5446e-01 | PDE Loss: 1.1988e-01 | Relative Error: 6.4049e-01 | Exact Solution MSE: 1.7157e+01\n",
      "Epoch 6/100 | Loss: 9.0666e-01 | PDE Loss: 1.0978e-01 | Relative Error: 6.0352e-01 | Exact Solution MSE: 1.5233e+01\n",
      "Epoch 7/100 | Loss: 8.7419e-01 | PDE Loss: 7.5702e-02 | Relative Error: 5.7030e-01 | Exact Solution MSE: 1.3602e+01\n",
      "Epoch 8/100 | Loss: 8.5594e-01 | PDE Loss: 8.8218e-02 | Relative Error: 5.3861e-01 | Exact Solution MSE: 1.2133e+01\n",
      "Epoch 9/100 | Loss: 8.1655e-01 | PDE Loss: 6.9106e-02 | Relative Error: 5.1020e-01 | Exact Solution MSE: 1.0887e+01\n",
      "Epoch 10/100 | Loss: 7.8304e-01 | PDE Loss: 6.8980e-02 | Relative Error: 4.8290e-01 | Exact Solution MSE: 9.7527e+00\n",
      "Epoch 11/100 | Loss: 7.4420e-01 | PDE Loss: 5.4648e-02 | Relative Error: 4.5724e-01 | Exact Solution MSE: 8.7438e+00\n",
      "Epoch 12/100 | Loss: 7.1651e-01 | PDE Loss: 5.4040e-02 | Relative Error: 4.3304e-01 | Exact Solution MSE: 7.8428e+00\n",
      "Epoch 13/100 | Loss: 6.9836e-01 | PDE Loss: 4.4644e-02 | Relative Error: 4.1047e-01 | Exact Solution MSE: 7.0467e+00\n",
      "Epoch 14/100 | Loss: 6.8748e-01 | PDE Loss: 3.8201e-02 | Relative Error: 3.8944e-01 | Exact Solution MSE: 6.3431e+00\n",
      "Epoch 15/100 | Loss: 6.7987e-01 | PDE Loss: 3.5103e-02 | Relative Error: 3.6929e-01 | Exact Solution MSE: 5.7037e+00\n",
      "Epoch 16/100 | Loss: 6.6942e-01 | PDE Loss: 3.4884e-02 | Relative Error: 3.5043e-01 | Exact Solution MSE: 5.1361e+00\n",
      "Epoch 17/100 | Loss: 6.6395e-01 | PDE Loss: 3.2623e-02 | Relative Error: 3.3235e-01 | Exact Solution MSE: 4.6196e+00\n",
      "Epoch 18/100 | Loss: 6.5934e-01 | PDE Loss: 3.1039e-02 | Relative Error: 3.1545e-01 | Exact Solution MSE: 4.1617e+00\n",
      "Epoch 19/100 | Loss: 6.5617e-01 | PDE Loss: 2.9377e-02 | Relative Error: 2.9926e-01 | Exact Solution MSE: 3.7455e+00\n",
      "Epoch 20/100 | Loss: 6.5343e-01 | PDE Loss: 2.8790e-02 | Relative Error: 2.8378e-01 | Exact Solution MSE: 3.3680e+00\n",
      "Epoch 21/100 | Loss: 6.5055e-01 | PDE Loss: 2.6180e-02 | Relative Error: 2.6919e-01 | Exact Solution MSE: 3.0307e+00\n",
      "Epoch 22/100 | Loss: 6.4788e-01 | PDE Loss: 2.6789e-02 | Relative Error: 2.5533e-01 | Exact Solution MSE: 2.7266e+00\n",
      "Epoch 23/100 | Loss: 6.4421e-01 | PDE Loss: 2.3547e-02 | Relative Error: 2.4219e-01 | Exact Solution MSE: 2.4531e+00\n",
      "Epoch 24/100 | Loss: 6.4229e-01 | PDE Loss: 2.3653e-02 | Relative Error: 2.2968e-01 | Exact Solution MSE: 2.2063e+00\n",
      "Epoch 25/100 | Loss: 6.4079e-01 | PDE Loss: 2.2699e-02 | Relative Error: 2.1779e-01 | Exact Solution MSE: 1.9838e+00\n",
      "Epoch 26/100 | Loss: 6.3957e-01 | PDE Loss: 2.2635e-02 | Relative Error: 2.0649e-01 | Exact Solution MSE: 1.7833e+00\n",
      "Epoch 27/100 | Loss: 6.3566e-01 | PDE Loss: 2.1163e-02 | Relative Error: 1.9566e-01 | Exact Solution MSE: 1.6010e+00\n",
      "Epoch 28/100 | Loss: 6.3265e-01 | PDE Loss: 2.0150e-02 | Relative Error: 1.8554e-01 | Exact Solution MSE: 1.4398e+00\n",
      "Epoch 29/100 | Loss: 6.3024e-01 | PDE Loss: 1.9173e-02 | Relative Error: 1.7587e-01 | Exact Solution MSE: 1.2936e+00\n",
      "Epoch 30/100 | Loss: 6.2939e-01 | PDE Loss: 1.9406e-02 | Relative Error: 1.6674e-01 | Exact Solution MSE: 1.1628e+00\n",
      "Epoch 31/100 | Loss: 6.2810e-01 | PDE Loss: 1.8385e-02 | Relative Error: 1.5802e-01 | Exact Solution MSE: 1.0443e+00\n",
      "Epoch 32/100 | Loss: 6.2747e-01 | PDE Loss: 1.8081e-02 | Relative Error: 1.4978e-01 | Exact Solution MSE: 9.3821e-01\n",
      "Epoch 33/100 | Loss: 6.2466e-01 | PDE Loss: 1.6991e-02 | Relative Error: 1.4187e-01 | Exact Solution MSE: 8.4180e-01\n",
      "Epoch 34/100 | Loss: 6.2181e-01 | PDE Loss: 1.6733e-02 | Relative Error: 1.3443e-01 | Exact Solution MSE: 7.5577e-01\n",
      "Epoch 35/100 | Loss: 6.1811e-01 | PDE Loss: 1.5699e-02 | Relative Error: 1.2737e-01 | Exact Solution MSE: 6.7855e-01\n",
      "Epoch 36/100 | Loss: 6.1527e-01 | PDE Loss: 1.5138e-02 | Relative Error: 1.2061e-01 | Exact Solution MSE: 6.0836e-01\n",
      "Epoch 37/100 | Loss: 6.1265e-01 | PDE Loss: 1.4002e-02 | Relative Error: 1.1426e-01 | Exact Solution MSE: 5.4600e-01\n",
      "Epoch 38/100 | Loss: 6.1050e-01 | PDE Loss: 1.3698e-02 | Relative Error: 1.0824e-01 | Exact Solution MSE: 4.8996e-01\n",
      "Epoch 39/100 | Loss: 6.0939e-01 | PDE Loss: 1.2819e-02 | Relative Error: 1.0261e-01 | Exact Solution MSE: 4.4037e-01\n",
      "Epoch 40/100 | Loss: 6.0792e-01 | PDE Loss: 1.2896e-02 | Relative Error: 9.7231e-02 | Exact Solution MSE: 3.9539e-01\n",
      "Epoch 41/100 | Loss: 6.0636e-01 | PDE Loss: 1.2104e-02 | Relative Error: 9.2269e-02 | Exact Solution MSE: 3.5606e-01\n",
      "Epoch 42/100 | Loss: 6.0527e-01 | PDE Loss: 1.2471e-02 | Relative Error: 8.7445e-02 | Exact Solution MSE: 3.1981e-01\n",
      "Epoch 43/100 | Loss: 6.0416e-01 | PDE Loss: 1.1747e-02 | Relative Error: 8.2931e-02 | Exact Solution MSE: 2.8764e-01\n",
      "Epoch 44/100 | Loss: 6.0245e-01 | PDE Loss: 1.2785e-02 | Relative Error: 7.8625e-02 | Exact Solution MSE: 2.5854e-01\n",
      "Epoch 45/100 | Loss: 6.0019e-01 | PDE Loss: 1.1426e-02 | Relative Error: 7.4606e-02 | Exact Solution MSE: 2.3279e-01\n",
      "Epoch 46/100 | Loss: 5.9821e-01 | PDE Loss: 1.1469e-02 | Relative Error: 7.0666e-02 | Exact Solution MSE: 2.0885e-01\n",
      "Epoch 47/100 | Loss: 5.9672e-01 | PDE Loss: 1.0446e-02 | Relative Error: 6.7116e-02 | Exact Solution MSE: 1.8840e-01\n",
      "Epoch 48/100 | Loss: 5.9589e-01 | PDE Loss: 1.0910e-02 | Relative Error: 6.3644e-02 | Exact Solution MSE: 1.6941e-01\n",
      "Epoch 49/100 | Loss: 5.9454e-01 | PDE Loss: 1.0228e-02 | Relative Error: 6.0264e-02 | Exact Solution MSE: 1.5189e-01\n",
      "Epoch 50/100 | Loss: 5.9367e-01 | PDE Loss: 1.0226e-02 | Relative Error: 5.7143e-02 | Exact Solution MSE: 1.3657e-01\n",
      "Epoch 51/100 | Loss: 5.9189e-01 | PDE Loss: 9.8901e-03 | Relative Error: 5.4205e-02 | Exact Solution MSE: 1.2289e-01\n",
      "Epoch 52/100 | Loss: 5.9069e-01 | PDE Loss: 9.7964e-03 | Relative Error: 5.1435e-02 | Exact Solution MSE: 1.1065e-01\n",
      "Epoch 53/100 | Loss: 5.8994e-01 | PDE Loss: 9.4157e-03 | Relative Error: 4.8957e-02 | Exact Solution MSE: 1.0024e-01\n",
      "Epoch 54/100 | Loss: 5.8903e-01 | PDE Loss: 9.3471e-03 | Relative Error: 4.6462e-02 | Exact Solution MSE: 9.0286e-02\n",
      "Epoch 55/100 | Loss: 5.8721e-01 | PDE Loss: 8.2819e-03 | Relative Error: 4.3697e-02 | Exact Solution MSE: 7.9860e-02\n",
      "Epoch 56/100 | Loss: 5.8570e-01 | PDE Loss: 8.8395e-03 | Relative Error: 4.1519e-02 | Exact Solution MSE: 7.2095e-02\n",
      "Epoch 57/100 | Loss: 5.8463e-01 | PDE Loss: 8.5916e-03 | Relative Error: 3.9446e-02 | Exact Solution MSE: 6.5078e-02\n",
      "Epoch 58/100 | Loss: 5.8387e-01 | PDE Loss: 8.8653e-03 | Relative Error: 3.7545e-02 | Exact Solution MSE: 5.8956e-02\n",
      "Epoch 59/100 | Loss: 5.8278e-01 | PDE Loss: 8.0880e-03 | Relative Error: 3.5596e-02 | Exact Solution MSE: 5.2994e-02\n",
      "Epoch 60/100 | Loss: 5.8216e-01 | PDE Loss: 8.6879e-03 | Relative Error: 3.3827e-02 | Exact Solution MSE: 4.7856e-02\n",
      "Epoch 61/100 | Loss: 5.8103e-01 | PDE Loss: 8.0594e-03 | Relative Error: 3.2090e-02 | Exact Solution MSE: 4.3068e-02\n",
      "Epoch 62/100 | Loss: 5.7842e-01 | PDE Loss: 8.9752e-03 | Relative Error: 3.0498e-02 | Exact Solution MSE: 3.8901e-02\n",
      "Epoch 63/100 | Loss: 5.7652e-01 | PDE Loss: 7.9365e-03 | Relative Error: 2.8944e-02 | Exact Solution MSE: 3.5037e-02\n",
      "Epoch 64/100 | Loss: 5.7618e-01 | PDE Loss: 7.7046e-03 | Relative Error: 2.7468e-02 | Exact Solution MSE: 3.1554e-02\n",
      "Epoch 65/100 | Loss: 5.7389e-01 | PDE Loss: 8.5565e-03 | Relative Error: 2.6022e-02 | Exact Solution MSE: 2.8321e-02\n",
      "Epoch 66/100 | Loss: 5.7211e-01 | PDE Loss: 7.0789e-03 | Relative Error: 2.4728e-02 | Exact Solution MSE: 2.5574e-02\n",
      "Epoch 67/100 | Loss: 5.7068e-01 | PDE Loss: 7.5104e-03 | Relative Error: 2.3475e-02 | Exact Solution MSE: 2.3048e-02\n",
      "Epoch 68/100 | Loss: 5.6958e-01 | PDE Loss: 6.9464e-03 | Relative Error: 2.2330e-02 | Exact Solution MSE: 2.0855e-02\n",
      "Epoch 69/100 | Loss: 5.6958e-01 | PDE Loss: 6.9940e-03 | Relative Error: 2.1328e-02 | Exact Solution MSE: 1.9025e-02\n",
      "Epoch 70/100 | Loss: 5.6727e-01 | PDE Loss: 8.2859e-03 | Relative Error: 2.0169e-02 | Exact Solution MSE: 1.7014e-02\n",
      "Epoch 71/100 | Loss: 5.6352e-01 | PDE Loss: 6.0275e-03 | Relative Error: 1.9264e-02 | Exact Solution MSE: 1.5521e-02\n",
      "Epoch 72/100 | Loss: 5.6232e-01 | PDE Loss: 6.3942e-03 | Relative Error: 1.8446e-02 | Exact Solution MSE: 1.4230e-02\n",
      "Epoch 73/100 | Loss: 5.6204e-01 | PDE Loss: 6.1066e-03 | Relative Error: 1.7772e-02 | Exact Solution MSE: 1.3210e-02\n",
      "Epoch 74/100 | Loss: 5.6115e-01 | PDE Loss: 6.1640e-03 | Relative Error: 1.7018e-02 | Exact Solution MSE: 1.2113e-02\n",
      "Epoch 75/100 | Loss: 5.6023e-01 | PDE Loss: 5.8752e-03 | Relative Error: 1.6323e-02 | Exact Solution MSE: 1.1143e-02\n",
      "Epoch 76/100 | Loss: 5.5920e-01 | PDE Loss: 6.4416e-03 | Relative Error: 1.5723e-02 | Exact Solution MSE: 1.0339e-02\n",
      "Epoch 77/100 | Loss: 5.5818e-01 | PDE Loss: 5.6159e-03 | Relative Error: 1.5178e-02 | Exact Solution MSE: 9.6347e-03\n",
      "Epoch 78/100 | Loss: 5.5811e-01 | PDE Loss: 5.7507e-03 | Relative Error: 1.4699e-02 | Exact Solution MSE: 9.0361e-03\n",
      "Epoch 79/100 | Loss: 5.5756e-01 | PDE Loss: 5.7808e-03 | Relative Error: 1.4314e-02 | Exact Solution MSE: 8.5691e-03\n",
      "Epoch 80/100 | Loss: 5.5713e-01 | PDE Loss: 5.4239e-03 | Relative Error: 1.3828e-02 | Exact Solution MSE: 7.9973e-03\n",
      "Epoch 81/100 | Loss: 5.5692e-01 | PDE Loss: 5.5568e-03 | Relative Error: 1.3486e-02 | Exact Solution MSE: 7.6067e-03\n",
      "Epoch 82/100 | Loss: 5.5667e-01 | PDE Loss: 5.5881e-03 | Relative Error: 1.3171e-02 | Exact Solution MSE: 7.2554e-03\n",
      "Epoch 83/100 | Loss: 5.5608e-01 | PDE Loss: 5.6931e-03 | Relative Error: 1.2864e-02 | Exact Solution MSE: 6.9212e-03\n",
      "Epoch 84/100 | Loss: 5.5566e-01 | PDE Loss: 5.4775e-03 | Relative Error: 1.2615e-02 | Exact Solution MSE: 6.6559e-03\n",
      "Epoch 85/100 | Loss: 5.5558e-01 | PDE Loss: 5.4137e-03 | Relative Error: 1.2425e-02 | Exact Solution MSE: 6.4566e-03\n",
      "Epoch 86/100 | Loss: 5.5557e-01 | PDE Loss: 5.4281e-03 | Relative Error: 1.2240e-02 | Exact Solution MSE: 6.2655e-03\n",
      "Epoch 87/100 | Loss: 5.5553e-01 | PDE Loss: 5.5259e-03 | Relative Error: 1.2057e-02 | Exact Solution MSE: 6.0798e-03\n",
      "Epoch 88/100 | Loss: 5.5454e-01 | PDE Loss: 5.7512e-03 | Relative Error: 1.1827e-02 | Exact Solution MSE: 5.8504e-03\n",
      "Epoch 89/100 | Loss: 5.5328e-01 | PDE Loss: 5.4103e-03 | Relative Error: 1.1629e-02 | Exact Solution MSE: 5.6558e-03\n",
      "Epoch 90/100 | Loss: 5.5290e-01 | PDE Loss: 5.0770e-03 | Relative Error: 1.1525e-02 | Exact Solution MSE: 5.5553e-03\n",
      "Epoch 91/100 | Loss: 5.5224e-01 | PDE Loss: 5.3143e-03 | Relative Error: 1.1370e-02 | Exact Solution MSE: 5.4070e-03\n",
      "Epoch 92/100 | Loss: 5.5181e-01 | PDE Loss: 4.9835e-03 | Relative Error: 1.1238e-02 | Exact Solution MSE: 5.2817e-03\n",
      "Epoch 93/100 | Loss: 6.1749e-01 | PDE Loss: 1.7520e-02 | Relative Error: 1.2195e-02 | Exact Solution MSE: 6.2200e-03\n",
      "Epoch 94/100 | Loss: 6.0146e-01 | PDE Loss: 1.2779e-02 | Relative Error: 1.1469e-02 | Exact Solution MSE: 5.5012e-03\n",
      "Epoch 95/100 | Loss: 5.9428e-01 | PDE Loss: 1.1292e-02 | Relative Error: 1.1313e-02 | Exact Solution MSE: 5.3527e-03\n",
      "Epoch 96/100 | Loss: 5.8510e-01 | PDE Loss: 9.6670e-03 | Relative Error: 1.1000e-02 | Exact Solution MSE: 5.0609e-03\n",
      "Epoch 97/100 | Loss: 5.8396e-01 | PDE Loss: 9.3280e-03 | Relative Error: 1.0864e-02 | Exact Solution MSE: 4.9361e-03\n",
      "Epoch 98/100 | Loss: 5.8374e-01 | PDE Loss: 9.2003e-03 | Relative Error: 1.0858e-02 | Exact Solution MSE: 4.9311e-03\n",
      "Epoch 99/100 | Loss: 5.7881e-01 | PDE Loss: 9.5190e-03 | Relative Error: 1.0698e-02 | Exact Solution MSE: 4.7865e-03\n",
      "Epoch 100/100 | Loss: 5.7457e-01 | PDE Loss: 7.4866e-03 | Relative Error: 1.0542e-02 | Exact Solution MSE: 4.6483e-03\n",
      "Total training time: 1025.19 seconds\n",
      "Saved true and predicted solutions to 'true_vs_predicted_solution.xlsx'\n",
      "Saved solutions at t=0.00 to 'solution_at_t_0.00.xlsx'\n",
      "Saved solutions at t=2.50 to 'solution_at_t_2.50.xlsx'\n",
      "Saved solutions at t=5.00 to 'solution_at_t_5.00.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set initial random seed for reproducibility\n",
    "init_seed = 0\n",
    "np.random.seed(init_seed)\n",
    "torch.manual_seed(init_seed)\n",
    "torch.cuda.manual_seed(init_seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "def fwd_gradients(Y, x):\n",
    "    \"\"\"\n",
    "    Compute the gradient of Y with respect to x.\n",
    "    Parameters:\n",
    "        Y (torch.Tensor): Output tensor.\n",
    "        x (torch.Tensor): Input tensor, gradients will be computed with respect to this.\n",
    "    Returns:\n",
    "        torch.Tensor: Gradient of Y with respect to x.\n",
    "    \"\"\"\n",
    "    dummy = torch.ones_like(Y)\n",
    "    G = torch.autograd.grad(Y, x, dummy, create_graph=True)[0]\n",
    "    return G\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Define the neural network architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_dim, X, device):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "        Parameters:\n",
    "            layer_dim (list): List containing the number of neurons in each layer.\n",
    "            X (numpy.ndarray): Input data, used for normalization.\n",
    "            device (torch.device): Device (CPU or GPU).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Calculate the mean and standard deviation for input normalization\n",
    "        self.X_mean = torch.from_numpy(X.mean(0, keepdims=True)).float().to(device)\n",
    "        self.X_std = torch.from_numpy(X.std(0, keepdims=True)).float().to(device)\n",
    "        \n",
    "        self.num_layers = len(layer_dim)\n",
    "        temp = []\n",
    "        \n",
    "        # Create the layers\n",
    "        for l in range(1, self.num_layers):\n",
    "            layer = torch.nn.Linear(layer_dim[l-1], layer_dim[l])\n",
    "            layer = weight_norm(layer, name='weight', dim=0)  # Apply weight normalization\n",
    "            torch.nn.init.normal_(layer.weight)  # Initialize weights using normal distribution\n",
    "            temp.append(layer)\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList(temp)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        Parameters:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        # Normalize the input using the computed mean and std\n",
    "        x = (x - self.X_mean) / self.X_std\n",
    "        for i in range(0, self.num_layers-1):\n",
    "            x = self.layers[i](x)\n",
    "            if i < self.num_layers-2:\n",
    "                x = torch.nn.functional.silu(x)  # Apply activation function (silu)\n",
    "        return x\n",
    "\n",
    "class TSONN:\n",
    "    \"\"\"\n",
    "    Physics-Informed Neural Network (PINN) for solving transient temperature field problems.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, device):\n",
    "        \"\"\"\n",
    "        Initialize the TSONN model.\n",
    "        Parameters:\n",
    "            layers (list): List containing the number of neurons in each layer.\n",
    "            device (torch.device): Device (CPU or GPU).\n",
    "        \"\"\"\n",
    "        self.Nx = 101  # Number of spatial grid points\n",
    "        self.Nt = 101  # Number of temporal grid points\n",
    "        self.layers = layers\n",
    "        self.device = device\n",
    "        \n",
    "        # Define the grid for spatial and temporal variables\n",
    "        t = torch.linspace(0.0, 5.0, self.Nt)\n",
    "        x = torch.linspace(0.0, 10.0, self.Nx)\n",
    "        xx, tt = torch.meshgrid(x, t, indexing='ij')\n",
    "        \n",
    "        # Create the reference grid (X_ref) for the model input\n",
    "        self.X_ref = torch.cat([xx.reshape(-1,1), tt.reshape(-1,1)], dim=1).to(self.device).requires_grad_(True)\n",
    "        \n",
    "        # Boundary and initial condition points\n",
    "        self.X_ic = torch.cat([xx[:, [0]], tt[:, [0]]], dim=1).to(self.device)\n",
    "        self.u_ic = torch.full_like(xx[:, [0]], -10, dtype=torch.float32, device=self.device)\n",
    "        self.X_lbc = torch.cat([xx[[0]], tt[[0]]], dim=0).T.to(self.device)\n",
    "        self.X_lbc.requires_grad = True\n",
    "        self.X_ubc = torch.cat([xx[[-1]], tt[[-1]]], dim=0).T.to(self.device)\n",
    "        self.X_ubc.requires_grad = True\n",
    "        \n",
    "        # Log dictionary to keep track of losses and metrics\n",
    "        self.log = {'losses':[], 'losses_b':[], 'losses_i':[], 'losses_f':[], 'losses_s':[], 'mse_exact':[], 'time':[]}\n",
    "        self.min_loss = 1\n",
    "        \n",
    "        # Initialize the neural network model\n",
    "        self.model = Net(layers, self.X_ref.cpu().detach().numpy(), self.device).to(self.device)\n",
    "\n",
    "    def exact_solution(self, z, t, alpha=0.016, beta_deg=33, L=10, psi_d=-10, c=0.104):\n",
    "        \"\"\"\n",
    "        Exact solution of the transient infiltration problem.\n",
    "        Parameters:\n",
    "            z (torch.Tensor): Spatial grid points.\n",
    "            t (torch.Tensor): Temporal grid points.\n",
    "            alpha, beta_deg, L, psi_d, c: Parameters for the exact solution.\n",
    "        Returns:\n",
    "            torch.Tensor: Exact solution at the given (z, t) points.\n",
    "        \"\"\"\n",
    "        beta = torch.tensor(beta_deg * torch.pi / 180.0, dtype=torch.float32, device=self.device)\n",
    "        z = z.to(self.device, dtype=torch.float32)\n",
    "        t = t.to(self.device, dtype=torch.float32)\n",
    "        alpha = torch.tensor(alpha, dtype=torch.float32, device=self.device)\n",
    "        psi_d = torch.tensor(psi_d, dtype=torch.float32, device=self.device)\n",
    "        L = torch.tensor(L, dtype=torch.float32, device=self.device)\n",
    "        c = torch.tensor(c, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Compute part of the exact solution\n",
    "        part_1 = (1 - torch.exp(alpha * psi_d)) * (1 - torch.exp(-alpha * torch.cos(beta) * z)) / (1 - torch.exp(-alpha * torch.cos(beta) * L))\n",
    "        sum_terms = 0\n",
    "        for k in range(1, 9999):\n",
    "            lambda_k = k * torch.pi / L\n",
    "            mu_k = (alpha**2 / 4 + lambda_k**2) / c\n",
    "            sum_terms += ((-1) ** k) * (lambda_k / mu_k) * torch.sin(lambda_k * z) * torch.exp(-mu_k * t)\n",
    "        \n",
    "        part_2 = (2 * (1 - torch.exp(alpha * psi_d)) / (L * c)) * torch.exp(alpha * torch.cos(beta) * (L - z) / 2) * sum_terms\n",
    "        u_true = 1/alpha * torch.log(part_1 + part_2 + torch.exp(alpha * psi_d))\n",
    "        \n",
    "        return u_true\n",
    "\n",
    "    def Msei(self):\n",
    "        \"\"\"\n",
    "        Initial condition loss (mean squared error between predicted and initial condition values).\n",
    "        \"\"\"\n",
    "        u = self.model(self.X_ic)\n",
    "        msei = F.mse_loss(u, self.u_ic)\n",
    "        return msei\n",
    "    \n",
    "    def Mseb(self):\n",
    "        \"\"\"\n",
    "        Boundary condition loss (mean squared error between predicted and boundary condition values).\n",
    "        \"\"\"\n",
    "        u_lbc = self.model(self.X_lbc)\n",
    "        u_ubc = self.model(self.X_ubc)\n",
    "        mseb = F.mse_loss(u_lbc, torch.full_like(u_lbc, -10, device=self.device)) + \\\n",
    "               F.mse_loss(u_ubc, torch.full_like(u_ubc, 0, device=self.device))\n",
    "        return mseb\n",
    "    \n",
    "    def TimeStepping(self):\n",
    "        \"\"\"\n",
    "        Perform one time step, store the current solution.\n",
    "        \"\"\"\n",
    "        u = self.model(self.X_ref)\n",
    "        self.U0 = u.detach()\n",
    "    \n",
    "    def Msef(self):\n",
    "        \"\"\"\n",
    "        PDE residual loss (based on the differential equation).\n",
    "        \"\"\"\n",
    "        beta = torch.tensor(33 * torch.pi / 180.0, dtype=torch.float32, device=self.device)\n",
    "        u = self.model(self.X_ref)\n",
    "        u_xt = fwd_gradients(u, self.X_ref)\n",
    "        u_x = u_xt[:,0:1]\n",
    "        u_t = u_xt[:,1:2]\n",
    "        u_xx = fwd_gradients(u_x, self.X_ref)[:,0:1]\n",
    "        \n",
    "        # Compute the PDE residual\n",
    "        f = u_t * 0.016 * 0.39 / 0.06 - u_xx - 0.016 * torch.cos(beta) * u_x - 0.016 * u_x ** 2\n",
    "        dt = 0.5\n",
    "        msef = 1/dt**2 * ((u - self.U0 + dt * f)**2).mean()\n",
    "        return msef\n",
    "    \n",
    "    def Mses(self):\n",
    "        \"\"\"\n",
    "        Relative L2 error between predicted solution and exact solution.\n",
    "        \"\"\"\n",
    "        z = self.X_ref[:, 0:1]\n",
    "        t = self.X_ref[:, 1:2]\n",
    "        u_true = self.exact_solution(z, t)\n",
    "        u_pred = self.model(self.X_ref)\n",
    "        mses = torch.norm(u_pred - u_true) / torch.norm(u_true)\n",
    "        return mses\n",
    "\n",
    "    def Loss(self):\n",
    "        \"\"\"\n",
    "        Total loss (sum of initial, boundary, PDE, and relative error losses).\n",
    "        \"\"\"\n",
    "        msei = self.Msei()\n",
    "        mseb = self.Mseb()\n",
    "        msef = self.Msef()\n",
    "        loss = msei + mseb + msef\n",
    "        return loss, msei, mseb, msef\n",
    "\n",
    "    def ResidualPoint(self):\n",
    "        \"\"\"\n",
    "        Generate random points for the residual calculation.\n",
    "        \"\"\"\n",
    "        t = torch.rand((10000, 1), device=self.device) * 5\n",
    "        z = torch.rand((10000, 1), device=self.device) * 10\n",
    "        self.X = torch.cat([z, t], dim=1).requires_grad_(True)\n",
    "\n",
    "    def train(self, epoch):\n",
    "        \"\"\"\n",
    "        Train the model for a given number of epochs.\n",
    "        \"\"\"\n",
    "        if len(self.log['time']) == 0:\n",
    "            t_start = time.time()\n",
    "        else:\n",
    "            t_start = time.time() - self.log['time'][-1]\n",
    "        \n",
    "        best_mse = float('inf')\n",
    "        \n",
    "        for i in range(epoch):\n",
    "            def closure():\n",
    "                self.optimizer.zero_grad()\n",
    "                self.loss, self.loss_i, self.loss_b, self.loss_f = self.Loss()\n",
    "                self.loss.backward()\n",
    "                return self.loss\n",
    "            \n",
    "            self.optimizer = torch.optim.LBFGS(self.model.parameters(), max_iter=100)\n",
    "            self.ResidualPoint()\n",
    "            self.TimeStepping()\n",
    "            self.optimizer.step(closure)\n",
    "            self.loss_s = self.Mses()\n",
    "            \n",
    "            z = self.X_ref[:, 0:1]\n",
    "            t = self.X_ref[:, 1:2]\n",
    "            u_true = self.exact_solution(z, t)\n",
    "            u_pred = self.model(self.X_ref)\n",
    "            mse_exact = F.mse_loss(u_pred, u_true)\n",
    "            self.log['mse_exact'].append(mse_exact.item())\n",
    "            \n",
    "            t_end = time.time()\n",
    "            elapsed = t_end - t_start\n",
    "            self.log['time'].append(elapsed)\n",
    "            t_start = time.time()\n",
    "            \n",
    "            self.log['losses'].append(self.loss.item())\n",
    "            self.log['losses_f'].append(self.loss_f.item())\n",
    "            self.log['losses_b'].append(self.loss_b.item())\n",
    "            self.log['losses_i'].append(self.loss_i.item())\n",
    "            self.log['losses_s'].append(self.loss_s.item())\n",
    "            \n",
    "            if mse_exact.item() < best_mse:\n",
    "                best_mse = mse_exact.item()\n",
    "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "            if (self.loss != self.loss) or ((i > 1) and (self.loss.item() > 3 * self.log['losses'][-2])):\n",
    "                if i == 0:\n",
    "                    self.model = Net(self.layers, self.X_ref.cpu().detach().numpy(), self.device).to(self.device)\n",
    "                    continue\n",
    "                else:\n",
    "                    self.model.load_state_dict(torch.load('best_model.pth'))\n",
    "                    print('Loading best model')\n",
    "                    self.ResidualPoint()\n",
    "                    self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "                    self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=100, gamma=0.9)\n",
    "                    continue\n",
    "                \n",
    "            self.TimeStepping()\n",
    "            \n",
    "            if (i+1) % 1 == 0 or (i+1) == epoch:\n",
    "                print(f'Epoch {i+1}/{epoch} | Loss: {self.loss.item():.4e} | PDE Loss: {self.loss_f.item():.4e} | Relative Error: {self.loss_s.item():.4e} | Exact Solution MSE: {mse_exact.item():.4e}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t1 = time.time()\n",
    "    torch.set_num_threads(1)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    layers = [2, 128, 128, 128, 128, 1]\n",
    "    nn = TSONN(layers, device)\n",
    "    nn.train(100)\n",
    "    t2 = time.time()\n",
    "    print(f'Total training time: {t2 - t1:.2f} seconds')\n",
    "\n",
    "    # Plot the loss and error evolution during training\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['losses']), label='Loss')\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['losses_s']), label='Relative L2 Error')\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['losses_f']), label='PDE Loss')\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['losses_b']), label='Boundary Loss')\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['losses_i']), label='Initial Loss')\n",
    "    plt.plot(nn.log['time'], np.log10(nn.log['mse_exact']), label='Exact Solution MSE')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Log10(Loss)')\n",
    "    plt.legend()\n",
    "    plt.title('Loss and Error During Training')\n",
    "    plt.savefig('loss_and_error.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Compare the predicted and exact solutions\n",
    "    XX = nn.X_ref[:, 0].cpu().detach().numpy().reshape(nn.Nx, nn.Nt)\n",
    "    TT = nn.X_ref[:, 1].cpu().detach().numpy().reshape(nn.Nx, nn.Nt)\n",
    "    z = nn.X_ref[:, 0:1]\n",
    "    t = nn.X_ref[:, 1:2]\n",
    "    u_pred = nn.model(nn.X_ref).cpu().detach().numpy().reshape(nn.Nx, nn.Nt)\n",
    "    u_true = nn.exact_solution(z, t).cpu().detach().numpy().reshape(nn.Nx, nn.Nt)\n",
    "    error = np.abs(u_true - u_pred)\n",
    "\n",
    "    # Plot heatmaps for reference solution, predicted solution, and absolute error\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    c1 = axs[0].pcolor(TT, XX, u_true, cmap='jet')\n",
    "    fig.colorbar(c1, ax=axs[0])\n",
    "    axs[0].set_xlabel('$t$')\n",
    "    axs[0].set_ylabel('$x$')\n",
    "    axs[0].set_title('Reference solution')\n",
    "    c2 = axs[1].pcolor(TT, XX, u_pred, cmap='jet')\n",
    "    fig.colorbar(c2, ax=axs[1])\n",
    "    axs[1].set_xlabel('$t$')\n",
    "    axs[1].set_ylabel('$x$')\n",
    "    axs[1].set_title('iTSONN solution')\n",
    "    c3 = axs[2].pcolor(TT, XX, error, cmap='jet')\n",
    "    fig.colorbar(c3, ax=axs[2])\n",
    "    axs[2].set_xlabel('$t$')\n",
    "    axs[2].set_ylabel('$x$')\n",
    "    axs[2].set_title('Absolute error')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('solution_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Plot solution comparisons at specific time points\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    time_indices = [0, 50, 100]\n",
    "    for idx, t_idx in enumerate(time_indices):\n",
    "        axs[idx].plot(XX[:,0], u_true[:,t_idx], label='Reference solution', color='blue')\n",
    "        axs[idx].plot(XX[:,0], u_pred[:,t_idx], '--', label='iTSONN solution', color='red')\n",
    "        axs[idx].set_xlabel('$x$')\n",
    "        axs[idx].set_ylabel('$u$')\n",
    "        axs[idx].set_title(f'$t = {TT[0, t_idx]:.2f}$')\n",
    "        axs[idx].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('solution_at_specific_times.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save the true and predicted solutions to Excel\n",
    "    u_true_flat = u_true.flatten()\n",
    "    u_pred_flat = u_pred.flatten()\n",
    "    x_flat = XX.flatten()\n",
    "    t_flat = TT.flatten()\n",
    "    data_all = {\n",
    "        'x': x_flat,\n",
    "        't': t_flat,\n",
    "        'True_Solution': u_true_flat,\n",
    "        'Predicted_Solution': u_pred_flat,\n",
    "        'Absolute_Error': np.abs(u_true_flat - u_pred_flat)\n",
    "    }\n",
    "    df_all = pd.DataFrame(data_all)\n",
    "    df_all.to_excel('true_vs_predicted_solution.xlsx', index=False)\n",
    "    print(\"Saved true and predicted solutions to 'true_vs_predicted_solution.xlsx'\")\n",
    "\n",
    "    # Save solutions at specific time points\n",
    "    for t_idx in time_indices:\n",
    "        t_value = TT[0, t_idx]\n",
    "        data_time = {\n",
    "            'x': XX[:, 0],\n",
    "            'True_Solution': u_true[:, t_idx],\n",
    "            'Predicted_Solution': u_pred[:, t_idx],\n",
    "            'Absolute_Error': np.abs(u_true[:, t_idx] - u_pred[:, t_idx])\n",
    "        }\n",
    "        df_time = pd.DataFrame(data_time)\n",
    "        filename = f'solution_at_t_{t_value:.2f}.xlsx'\n",
    "        df_time.to_excel(filename, index=False)\n",
    "        print(f\"Saved solutions at t={t_value:.2f} to '{filename}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
